{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9374fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Unversity\\KeyValueMemory\\kv_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54690a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"antareepdey/Patient_doctor_chat\")\n",
    "datasets = [i['Text'] for i in data['train']]\n",
    "patient_query = []\n",
    "doctor_response = []\n",
    "\n",
    "for i in range(1000):\n",
    "    inputs, outputs = datasets[i].split(\"###Output:\")\n",
    "    patient_query.append(inputs.replace(\"###Input:\",\"\"))\n",
    "    doctor_response.append(outputs)\n",
    "data = {\"Patient query\": patient_query, \"Doctor response\": doctor_response}\n",
    "df = pd.DataFrame(data=data)\n",
    "def preprocess_data(text):\n",
    "    # preprocess\n",
    "    text = text.lower()\n",
    "    text = text.replace('?','')\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\",\",\" \")\n",
    "    text = text.replace(\"1)\",\" \")\n",
    "    text = text.replace(\"2)\",\" \")\n",
    "    text = text.replace(\"3)\",\" \")\n",
    "    text = text.replace(\"4)\",\" \")\n",
    "    text = text.replace(\".\",\" \")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['Patient query'] = df['Patient query'].apply(preprocess_data)\n",
    "df['Doctor response'] = df['Doctor response'].apply(preprocess_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-Embedding-0.6B', padding_side='left')\n",
    "embed_model = AutoModel.from_pretrained('Qwen/Qwen3-Embedding-0.6B')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a314fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.max_length = 8192\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        question = df.iloc[index]['Patient query']\n",
    "        answer = df.iloc[index]['Doctor response']\n",
    "\n",
    "        question_ids = tokenizer(\n",
    "            question,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )['input_ids'][0] \n",
    "\n",
    "        answer_ids = tokenizer(\n",
    "            answer,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )['input_ids'][0]\n",
    "\n",
    "        return question_ids, answer_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac15a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch) \n",
    "\n",
    "    padded_questions = pad_sequence(questions, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    padded_answers = pad_sequence(answers, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return padded_questions, padded_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d546c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8aa7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader( dataset, batch_size=8, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d00f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderWithKBAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, embedding_dim=1024):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.decoder = nn.LSTMCell(embedding_dim, hidden_dim*2)\n",
    "\n",
    "        # Attention over encoder outputs\n",
    "        self.W_denc1 = nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        self.W_denc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Attention over KB keys\n",
    "        self.W_kb1 = nn.Linear(hidden_dim + embedding_dim, hidden_dim)\n",
    "        self.W_kb2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.r = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Final vocab projection\n",
    "        self.U = nn.Linear(hidden_dim * 4, vocab_size)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "\n",
    "    def decoder_attention(self, decoder_hidden, encoder_hidden):\n",
    "        #print(encoder_hidden.shape)\n",
    "        B, T, H = encoder_hidden.shape\n",
    "        decoder_exp = decoder_hidden.unsqueeze(1).expand(-1, T, -1)     # (B, T, H)\n",
    "        #print(decoder_exp.shape)\n",
    "        combined = torch.cat([encoder_hidden, decoder_exp], dim=2)     # (B, T, 2H)\n",
    "        #print(combined.shape)\n",
    "        x = torch.tanh(self.W_denc1(combined))                          # (B, T, H)\n",
    "        #print(x.shape)\n",
    "        x = torch.tanh(self.W_denc2(x))                                 # (B, T, H)\n",
    "        #print(x.shape)\n",
    "        u = self.w(x).squeeze(-1)                                       # (B, T)\n",
    "        #print(u.shape)\n",
    "        attn = torch.softmax(u, dim=1)                                  # (B, T)\n",
    "        #print(attn.shape)\n",
    "\n",
    "        context = torch.bmm(attn.unsqueeze(1), encoder_hidden).squeeze(1)  # (B, H)\n",
    "        #print(context.shape)\n",
    "        concat = torch.cat([decoder_hidden, context], dim=1)           # (B, 2H)\n",
    "        #print(concat.shape)\n",
    "        vocab_logits = self.U(concat)                                   # (B, vocab_size)\n",
    "        return vocab_logits\n",
    "\n",
    "    def kb_attention(self, decoder_hidden, kb_keys):\n",
    "        B, H = decoder_hidden.shape\n",
    "        num_kb = kb_keys.shape[0]\n",
    "\n",
    "        decoder_exp = decoder_hidden.unsqueeze(1).expand(-1, num_kb, -1)        # (B, num_kb, H)\n",
    "        kb_keys_exp = kb_keys.squeeze(1).unsqueeze(0).expand(B, -1, -1)         # (B, num_kb, E)\n",
    "\n",
    "        combined = torch.cat([kb_keys_exp, decoder_exp], dim=-1)                # (B, num_kb, H+E)\n",
    "        x = torch.tanh(self.W_kb1(combined))                                    # (B, num_kb, H)\n",
    "        \n",
    "        x = torch.tanh(self.W_kb2(x))                                           # (B, num_kb, H)\n",
    "        scores = self.r(x).squeeze(-1)                                          # (B, num_kb)\n",
    "        return scores\n",
    "\n",
    "    def forward(self, inputs, targets, kb_keys=None, teacher_forcing=True, fine_tune=False):\n",
    "        #print(targets.shape)\n",
    "        batch, T_out , _ = targets.shape\n",
    "        \n",
    "        enc_out, (h_enc, c_enc) = self.encoder(inputs)             # enc_out: (B, T_in, H)\n",
    "        # print(\"enc out\", enc_out.shape)\n",
    "        # print(\"h_enc\",h_enc.shape)\n",
    "        # print(\"c_enc\", c_enc.shape)\n",
    "        #print(h_enc[0,:,:].unsqueeze(0).shape)\n",
    "        hidden, cell = torch.cat([h_enc[0],h_enc[-1]], dim=-1), torch.cat([c_enc[0], c_enc[1]], dim=-1)\n",
    "        #print(hidden.shape)\n",
    "       \n",
    "        #print(\"start\",start_token)\n",
    "        logits = []\n",
    "        \n",
    "        #print(targets[0].shape)\n",
    "        dec_input = targets[:,0,:]                   # (B, E)\n",
    "\n",
    "        #print(\"dec_input\",dec_input[-1].unsqueeze(0))\n",
    "        #print(\"hidden_cell\", hidden.shape)\n",
    "        for t in range(1, T_out):\n",
    "            #print(\"incode input shape\", dec_input.shape)\n",
    "            hidden_logits, cell = self.decoder(dec_input, (hidden, cell))      # (B, H)\n",
    "            #print(\"hiddne_logits\", hidden_logits.shape)\n",
    "            #print(enc_out.shape)\n",
    "            hidden_logits = self.decoder_attention(hidden_logits, enc_out)      # (B, V)\n",
    "            #print(hidden_logits)\n",
    "            if fine_tune:\n",
    "                kb_logits = self.kb_attention(hidden, kb_keys)              # (B, n)\n",
    "                hidden_logits = torch.cat([hidden_logits, kb_logits], dim=1)  # (B, V+n)\n",
    "                \n",
    "            logits.append(hidden_logits)  \n",
    "            #print(hidden_logits.shape)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                #target = targets[:, t].unsqueeze(0)\n",
    "                #dec_input = self.embedding(target)['last_hidden_state'][0]\n",
    "                #print(dec_input.shape)\n",
    "                dec_input = targets[:,t,:]\n",
    "            else:\n",
    "                pred = torch.argmax(hidden_logits, dim=1)\n",
    "                pred = torch.where(pred < self.vocab_size, pred, torch.tensor(0).to(pred.device))\n",
    "\n",
    "        return torch.stack(logits, dim=1)  # (B, T_out-1, V+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652500de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "model = EncoderDecoderWithKBAttention(vocab_size=vocab_size,hidden_dim=320, embedding_dim=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a767dff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "maxlength = 8192\n",
    "start_token = tokenizer(\n",
    "        '<|im_start|>',\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "110392b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (embed_tokens): Embedding(151669, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x Qwen3DecoderLayer(\n",
       "      (self_attn): Qwen3Attention(\n",
       "        (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "      )\n",
       "      (mlp): Qwen3MLP(\n",
       "        (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "  (rotary_emb): Qwen3RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "297eb140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 130, 151669])\n",
      "torch.Size([8, 131])\n"
     ]
    }
   ],
   "source": [
    "for input, target in train_loader:\n",
    "    input = embed_model(input)['last_hidden_state']\n",
    "    #print(input.shape)\n",
    "    #print(target.shape)\n",
    "    batch_size = target.shape[0]\n",
    "    target = torch.cat([start_token[:,0].repeat(batch_size, 1),target] , dim=1)\n",
    "    #print(target.shape)\n",
    "    outputs = embed_model(target)['last_hidden_state']\n",
    "    #print(outputs)\n",
    "    #print(outputs.shape)\n",
    "    #print(input.shape)\n",
    "    #print(input)\n",
    "    input = input.to(device)\n",
    "    outputs = outputs.to(device)\n",
    "    target = target.to(device)\n",
    "    logits =  model(input, outputs,device)\n",
    "    # #print(target[0][1:].unsqueeze(0).shape)\n",
    "    print(logits.shape)\n",
    "    print(target.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a635eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 1: 100%|██████████| 125/125 [09:24<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 2: 100%|██████████| 125/125 [09:23<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 4.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 3: 100%|██████████| 125/125 [09:09<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 3.6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 4: 100%|██████████| 125/125 [09:13<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 3.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 5: 100%|██████████| 125/125 [09:00<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 2.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 6: 100%|██████████| 125/125 [09:28<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 2.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 7: 100%|██████████| 125/125 [09:35<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 2.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 8: 100%|██████████| 125/125 [09:07<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 2.3755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 9: 100%|██████████| 125/125 [09:09<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 2.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 10:  42%|████▏     | 53/125 [03:57<05:03,  4.21s/it]"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for input, target in tqdm(train_loader, desc=f\"Training Epochs - {epoch+1}\"):\n",
    "        \n",
    "        #print(input.shape)\n",
    "        #print(target.shape)\n",
    "        batch_size = target.shape[0]\n",
    "        target = torch.cat([start_token[:,0].repeat(batch_size, 1),target] , dim=1)\n",
    "        #print(target.shape)\n",
    "        with torch.no_grad():\n",
    "            input = embed_model(input)['last_hidden_state']\n",
    "            outputs = embed_model(target)['last_hidden_state']\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(input.shape)\n",
    "        #print(input)\n",
    "        input = input.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        target = target.to(device)\n",
    "        logits =  model(input, outputs,device)\n",
    "        \n",
    "        # input = input.to(device)\n",
    "        # target = target.to(device)\n",
    "        # target = torch.cat([start_token,target, end_token] , dim=1)\n",
    "        # outputs = embed_model(target)['last_hidden_state'][0]\n",
    "        # # print(\"input shape\",input.shape)\n",
    "        # # print(\"len \", len(input))\n",
    "        # if input.shape[1]==0:\n",
    "        #     continue\n",
    "        optimizer.zero_grad()\n",
    "        # logits = model(input,outputs,device)  # (B, T-1, V+K)\n",
    "        target_trimmed = target[:, 1:]  \n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]),\n",
    "            target_trimmed.reshape(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(loss)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_loss.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Hi doctor,I have a small white scar on the lower lip for seven months. It was not white at first. But now it just stays there and does not show any change.\"\n",
    "input = preprocess_data(input)\n",
    "start_token = tokenizer(\n",
    "        '<|im_start|>',\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids']\n",
    "input_tokens = tokenizer(\n",
    "        input,\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids']\n",
    "\n",
    "embed_query = embed_model(input_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text_token = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
