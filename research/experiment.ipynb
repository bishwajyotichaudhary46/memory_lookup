{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9374fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Unversity\\KeyValueMemory\\kv_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54690a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"antareepdey/Patient_doctor_chat\")\n",
    "datasets = [i['Text'] for i in data['train']]\n",
    "patient_query = []\n",
    "doctor_response = []\n",
    "patient_query_val = []\n",
    "doctor_response_val = []\n",
    "\n",
    "for i in range(1000):\n",
    "    inputs, outputs = datasets[i].split(\"###Output:\")\n",
    "    patient_query.append(inputs.replace(\"###Input:\",\"\"))\n",
    "    doctor_response.append(outputs)\n",
    "for i in range(1000,1200):\n",
    "    inputs, outputs = datasets[i].split(\"###Output:\")\n",
    "    patient_query_val.append(inputs.replace(\"###Input:\",\"\"))\n",
    "    doctor_response_val.append(outputs)\n",
    "\n",
    "data = {\"Patient query\": patient_query, \"Doctor response\": doctor_response}\n",
    "val_data = {\"Patient query\": patient_query_val, \"Doctor response\": doctor_response_val}\n",
    "df = pd.DataFrame(data=data)\n",
    "val_df = pd.DataFrame(data=val_data)\n",
    "def preprocess_data(text):\n",
    "    # preprocess\n",
    "    text = text.lower()\n",
    "    text = text.replace('?','')\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\",\",\" \")\n",
    "    text = text.replace(\"1)\",\" \")\n",
    "    text = text.replace(\"2)\",\" \")\n",
    "    text = text.replace(\"3)\",\" \")\n",
    "    text = text.replace(\"4)\",\" \")\n",
    "    text = text.replace(\".\",\" \")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['Patient query'] = df['Patient query'].apply(preprocess_data)\n",
    "df['Doctor response'] = df['Doctor response'].apply(preprocess_data)\n",
    "\n",
    "val_df['Patient query'] = val_df['Patient query'].apply(preprocess_data)\n",
    "val_df['Doctor response'] = val_df['Doctor response'].apply(preprocess_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-Embedding-0.6B', padding_side='left')\n",
    "embed_model = AutoModel.from_pretrained('Qwen/Qwen3-Embedding-0.6B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a314fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.max_length = 8192\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        question = df.iloc[index]['Patient query']\n",
    "        answer = df.iloc[index]['Doctor response']\n",
    "\n",
    "        question_ids = tokenizer(\n",
    "            question,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )['input_ids'][0] \n",
    "\n",
    "        answer_ids = tokenizer(\n",
    "            answer,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )['input_ids'][0]\n",
    "\n",
    "        return question_ids, answer_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac15a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch) \n",
    "\n",
    "    padded_questions = pad_sequence(questions, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    padded_answers = pad_sequence(answers, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return padded_questions, padded_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d546c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(df) \n",
    "val_dataset = CustomDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8aa7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader( dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader( val_dataset, batch_size=1,  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d00f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892b0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderWithKBAttention(nn.Module):\n",
    "    def __init__(self, embed_model , vocab_size, hidden_dim, embedding_dim=1024):\n",
    "        super().__init__()\n",
    "        self.embed_model = embed_model\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.decoder = nn.LSTMCell(embedding_dim, hidden_dim*2)\n",
    "\n",
    "        # Attention over encoder outputs\n",
    "        self.W_denc1 = nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        self.W_denc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.w = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Attention over KB keys\n",
    "        self.W_kb1 = nn.Linear(hidden_dim + embedding_dim, hidden_dim)\n",
    "        self.W_kb2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.r = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Final vocab projection\n",
    "        self.U = nn.Linear(hidden_dim * 4, vocab_size)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "\n",
    "    def decoder_attention(self, decoder_hidden, encoder_hidden):\n",
    "        #print(encoder_hidden.shape)\n",
    "        B, T, H = encoder_hidden.shape\n",
    "        decoder_exp = decoder_hidden.unsqueeze(1).expand(-1, T, -1)     # (B, T, H)\n",
    "        #print(decoder_exp.shape)\n",
    "        combined = torch.cat([encoder_hidden, decoder_exp], dim=2)     # (B, T, 2H)\n",
    "        #print(combined.shape)\n",
    "        x = torch.tanh(self.W_denc1(combined))                          # (B, T, H)\n",
    "        #print(x.shape)\n",
    "        x = torch.tanh(self.W_denc2(x))                                 # (B, T, H)\n",
    "        #print(x.shape)\n",
    "        u = self.w(x).squeeze(-1)                                       # (B, T)\n",
    "        #print(u.shape)\n",
    "        attn = torch.softmax(u, dim=1)                                  # (B, T)\n",
    "        #print(attn.shape)\n",
    "\n",
    "        context = torch.bmm(attn.unsqueeze(1), encoder_hidden).squeeze(1)  # (B, H)\n",
    "        #print(context.shape)\n",
    "        concat = torch.cat([decoder_hidden, context], dim=1)           # (B, 2H)\n",
    "        #print(concat.shape)\n",
    "        vocab_logits = self.U(concat)                                   # (B, vocab_size)\n",
    "        return vocab_logits\n",
    "\n",
    "    def kb_attention(self, decoder_hidden, kb_keys):\n",
    "        B, H = decoder_hidden.shape\n",
    "        num_kb = kb_keys.shape[0]\n",
    "\n",
    "        decoder_exp = decoder_hidden.unsqueeze(1).expand(-1, num_kb, -1)        # (B, num_kb, H)\n",
    "        kb_keys_exp = kb_keys.squeeze(1).unsqueeze(0).expand(B, -1, -1)         # (B, num_kb, E)\n",
    "\n",
    "        combined = torch.cat([kb_keys_exp, decoder_exp], dim=-1)                # (B, num_kb, H+E)\n",
    "        x = torch.tanh(self.W_kb1(combined))                                    # (B, num_kb, H)\n",
    "        \n",
    "        x = torch.tanh(self.W_kb2(x))                                           # (B, num_kb, H)\n",
    "        scores = self.r(x).squeeze(-1)                                          # (B, num_kb)\n",
    "        return scores\n",
    "\n",
    "    def forward(self, inputs, targets, inference = False, teacher_forcing=True,  kb_keys=None,  fine_tune=False):\n",
    "        #print(targets.shape)\n",
    "        batch, T_out , _ = targets.shape\n",
    "        \n",
    "        enc_out, (h_enc, c_enc) = self.encoder(inputs)             # enc_out: (B, T_in, H)\n",
    "        # print(\"enc out\", enc_out.shape)\n",
    "        # print(\"h_enc\",h_enc.shape)\n",
    "        # print(\"c_enc\", c_enc.shape)\n",
    "        #print(h_enc[0,:,:].unsqueeze(0).shape)\n",
    "        hidden, cell = torch.cat([h_enc[0],h_enc[-1]], dim=-1), torch.cat([c_enc[0], c_enc[1]], dim=-1)\n",
    "        #print(hidden.shape)\n",
    "       \n",
    "        #print(\"start\",start_token)\n",
    "        logits = []\n",
    "        \n",
    "        #print(targets[0].shape)\n",
    "        dec_input = targets[:,0,:]                   # (B, E)\n",
    "        #print(dec_input)\n",
    "\n",
    "        #print(\"dec_input\",dec_input[-1].unsqueeze(0))\n",
    "        #print(\"hidden_cell\", hidden.shape)\n",
    "        if inference:\n",
    "            #print(\"incode input shape\", dec_input.shape)\n",
    "            hidden_logits, cell = self.decoder(dec_input, (hidden, cell))      # (B, H)\n",
    "            #print(\"hiddne_logits\", hidden_logits.shape)\n",
    "            #print(enc_out.shape)\n",
    "            hidden_logits = self.decoder_attention(hidden_logits, enc_out)      # (B, V)\n",
    "            #print(hidden_logits)\n",
    "            if fine_tune:\n",
    "                kb_logits = self.kb_attention(hidden, kb_keys)              # (B, n)\n",
    "                hidden_logits = torch.cat([hidden_logits, kb_logits], dim=1)  # (B, V+n)\n",
    "                \n",
    "            logits.append(hidden_logits)  \n",
    "            #print(hidden_logits.shape)\n",
    "\n",
    "            if teacher_forcing:\n",
    "                #target = targets[:, t].unsqueeze(0)\n",
    "                #dec_input = self.embedding(target)['last_hidden_state'][0]\n",
    "                #print(dec_input.shape)\n",
    "                dec_input = targets[:,t,:]\n",
    "            else:\n",
    "                pred = torch.argmax(hidden_logits, dim=1)\n",
    "                pred = torch.where(pred < self.vocab_size, pred, torch.tensor(0).to(pred.device))\n",
    "        else:\n",
    "            for t in range(1, T_out):\n",
    "                #print(\"incode input shape\", dec_input.shape)\n",
    "                hidden_logits, cell = self.decoder(dec_input, (hidden, cell))      # (B, H)\n",
    "                #print(\"hiddne_logits\", hidden_logits.shape)\n",
    "                #print(enc_out.shape)\n",
    "                hidden_logits = self.decoder_attention(hidden_logits, enc_out)      # (B, V)\n",
    "                #print(hidden_logits)\n",
    "                if fine_tune:\n",
    "                    kb_logits = self.kb_attention(hidden, kb_keys)              # (B, n)\n",
    "                    hidden_logits = torch.cat([hidden_logits, kb_logits], dim=1)  # (B, V+n)\n",
    "                    \n",
    "                logits.append(hidden_logits)  \n",
    "                #print(hidden_logits.shape)\n",
    "\n",
    "                if teacher_forcing:\n",
    "                    #target = targets[:, t].unsqueeze(0)\n",
    "                    #dec_input = self.embedding(target)['last_hidden_state'][0]\n",
    "                    #print(dec_input.shape)\n",
    "                    dec_input = targets[:,t,:]\n",
    "                else:\n",
    "                    pred = torch.argmax(hidden_logits, dim=1)\n",
    "                    pred = torch.where(pred < self.vocab_size, pred, torch.tensor(0).to(pred.device))\n",
    "\n",
    "        return torch.stack(logits, dim=1)  # (B, T_out-1, V+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "652500de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "model = EncoderDecoderWithKBAttention(embed_model=embed_model, vocab_size=vocab_size, hidden_dim=320, embedding_dim=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a767dff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "maxlength = 8192\n",
    "start_token = tokenizer(\n",
    "        '<|im_start|>',\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9b129a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644, 151643]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "110392b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (embed_tokens): Embedding(151669, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x Qwen3DecoderLayer(\n",
       "      (self_attn): Qwen3Attention(\n",
       "        (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "      )\n",
       "      (mlp): Qwen3MLP(\n",
       "        (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "  (rotary_emb): Qwen3RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9568237",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embed_model =  AutoModel.from_pretrained('Qwen/Qwen3-Embedding-0.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "297eb140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 173, 151669])\n",
      "torch.Size([8, 174])\n"
     ]
    }
   ],
   "source": [
    "for input, target in train_loader:\n",
    "    input = new_embed_model(input)['last_hidden_state']\n",
    "    #print(input.shape)\n",
    "    #print(target.shape)\n",
    "    batch_size = target.shape[0]\n",
    "    target = torch.cat([start_token[:,0].repeat(batch_size, 1),target] , dim=1)\n",
    "    #print(target.shape)\n",
    "    outputs = new_embed_model(target)['last_hidden_state']\n",
    "    #print(outputs)\n",
    "    #print(outputs.shape)\n",
    "    #print(input.shape)\n",
    "    #print(input)\n",
    "    input = input.to(device)\n",
    "    outputs = outputs.to(device)\n",
    "    target = target.to(device)\n",
    "    logits =  model(input, outputs)\n",
    "    # #print(target[0][1:].unsqueeze(0).shape)\n",
    "    print(logits.shape)\n",
    "    print(target.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a635eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 25\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#weight_decay = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 1: 100%|██████████| 125/125 [09:57<00:00,  4.78s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:34<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 4.0543 , Val Loss: 2.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 2: 100%|██████████| 125/125 [10:02<00:00,  4.82s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:38<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.4440 , Val Loss: 1.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 3: 100%|██████████| 125/125 [10:28<00:00,  5.03s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:40<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.9312 , Val Loss: 1.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 4: 100%|██████████| 125/125 [10:39<00:00,  5.12s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:41<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.5467 , Val Loss: 1.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 5: 100%|██████████| 125/125 [10:40<00:00,  5.13s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:31<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1.2866 , Val Loss: 1.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 6: 100%|██████████| 125/125 [10:29<00:00,  5.03s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:38<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1.1229 , Val Loss: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 7: 100%|██████████| 125/125 [10:34<00:00,  5.07s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:43<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.9661 , Val Loss: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 8: 100%|██████████| 125/125 [10:38<00:00,  5.11s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:41<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.8323 , Val Loss: 0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 9: 100%|██████████| 125/125 [10:23<00:00,  4.99s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:39<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.7298 , Val Loss: 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 10: 100%|██████████| 125/125 [10:38<00:00,  5.11s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:38<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6198 , Val Loss: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 11: 100%|██████████| 125/125 [10:34<00:00,  5.08s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:40<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.5292 , Val Loss: 0.4396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 12: 100%|██████████| 125/125 [09:59<00:00,  4.80s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:36<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.4502 , Val Loss: 0.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 13: 100%|██████████| 125/125 [10:14<00:00,  4.92s/it]\n",
      "Validation: 100%|██████████| 25/25 [01:39<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.3901 , Val Loss: 0.3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs - 14:  13%|█▎        | 16/125 [01:23<09:17,  5.12s/it]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7093905",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "646d2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14990, 10668]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input = \"Hello doctor\"\n",
    "input = preprocess_data(input)\n",
    "start_token = tokenizer(\n",
    "        '<|im_start|>',\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids'][:,0].unsqueeze(0).to(device)\n",
    "input_tokens = tokenizer(\n",
    "        input,\n",
    "        max_length= maxlength,\n",
    "        return_tensors=\"pt\",\n",
    "    )['input_ids'][:, :-1].to(device)\n",
    "\n",
    "print(input_tokens)\n",
    "embed_model = embed_model.to(device)\n",
    "\n",
    "embed_query = embed_model(input_tokens)['last_hidden_state'].to(device)\n",
    "target = embed_model(start_token)['last_hidden_state'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc5223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"../models/model_weights_024.pth\")\n",
    "load_result = model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cea9d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effff484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66efb32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151644"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_token.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a19a44ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2152\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n",
      "1850\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure the model is in eval mode for inference\n",
    "model.eval()\n",
    "tokens = []\n",
    "token = start_token.item()\n",
    "# Now call the model, not `load_result`:\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        logits = model(embed_query, target, True, False)\n",
    "        token = torch.argmax(logits[0], dim=1)\n",
    "        target = embed_model(token.unsqueeze(0))['last_hidden_state'].to(device)\n",
    "        token = token.item()\n",
    "        tokens.append(token)\n",
    "        print(token)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a1af6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12649b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest',\n",
       " 'Ġbest']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41efd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = torch.argmax(logits[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c65e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41e556af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list.append(token.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a4b07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([9330], device='cuda:0'), 9330]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43149cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[  2.3688, -15.1576,  -0.0910,  ...,  -7.9240, -11.6597,   0.9951]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>), past_key_values=<transformers.cache_utils.DynamicCache object at 0x00000201FF880190>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model(token.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db4be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc9b8c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(9330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a648df01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "649c8adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644, 151643]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fde2d4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.8472,  -4.0913,   0.2632,  ...,  -4.2332, -10.3624,   0.6719]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86769c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 1000/1000 [17:54<00:00,  1.07s/it]\n",
      "Validating: 100%|██████████| 200/200 [01:53<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.3553, Val Loss: 0.3077, Train Acc: 0.8887, Val Acc: 0.9055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 1000/1000 [18:07<00:00,  1.09s/it]\n",
      "Validating: 100%|██████████| 200/200 [01:39<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.3111, Val Loss: 0.2604, Train Acc: 0.9036, Val Acc: 0.9212\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(23,epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_val_loss = 0.0\n",
    "    total_train_correct = 0\n",
    "    total_train_tokens = 0\n",
    "\n",
    "    for input_texts, target_tokens in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        batch_size = target_tokens.size(0)\n",
    "        input_texts = input_texts[:, :-1]\n",
    "\n",
    "        target_with_bos = torch.cat([start_token[:, 0].repeat(batch_size, 1), target_tokens], dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_embeds = new_embed_model(input_texts)['last_hidden_state']\n",
    "            target_embeds = new_embed_model(target_with_bos)['last_hidden_state']\n",
    "\n",
    "        input_embeds = input_embeds.to(device)\n",
    "        target_embeds = target_embeds.to(device)\n",
    "        target_tokens = target_tokens.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_embeds, target_embeds)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.view(-1, logits.shape[-1]),\n",
    "            target_tokens.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct = (preds == target_tokens).float()\n",
    "        total_train_correct += correct.sum().item()\n",
    "        total_train_tokens += target_tokens.numel()\n",
    "\n",
    "    model.eval()\n",
    "    total_val_correct = 0\n",
    "    total_val_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_texts, target_tokens in tqdm(val_loader, desc=\"Validating\"):\n",
    "            batch_size = target_tokens.size(0)\n",
    "            target_with_bos = torch.cat([start_token[:, 0].repeat(batch_size, 1), target_tokens], dim=1)\n",
    "\n",
    "            input_embeds = new_embed_model(input_texts)['last_hidden_state']\n",
    "            target_embeds = new_embed_model(target_with_bos)['last_hidden_state']\n",
    "\n",
    "            input_embeds = input_embeds.to(device)\n",
    "            target_embeds = target_embeds.to(device)\n",
    "            target_tokens = target_tokens.to(device)\n",
    "\n",
    "            logits = model(input_embeds, target_embeds)\n",
    "\n",
    "            loss = criterion(\n",
    "                logits.view(-1, logits.shape[-1]),\n",
    "                target_tokens.reshape(-1)\n",
    "            )\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct = (preds == target_tokens).float()\n",
    "            total_val_correct += correct.sum().item()\n",
    "            total_val_tokens += target_tokens.numel()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    train_accuracy = total_train_correct / total_train_tokens\n",
    "    val_accuracy = total_val_correct / total_val_tokens\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"../models/model_weights_0{epoch}.pth\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a738e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = [0.8739, 0.8879, 0.9021, 0.9004, 0.9212]\n",
    "train_acc = [0.8456, 0.8663, 0.8772, 0.8773, 0.9036]\n",
    "train_loss = [0.5003, 0.4344, 0.4007, 0.3974, 0.3111]\n",
    "val_loss = [0.4197, 0.3763, 0.3406, 0.3411, 0.2604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad367e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cf904be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7696d54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3917e+00,  1.2132e+00, -1.8796e-01,  ..., -8.5305e+00,\n",
       "          -1.1822e+01, -4.7525e-03],\n",
       "         [ 2.0638e-01, -4.2831e+00, -1.1676e+00,  ..., -2.1979e+00,\n",
       "          -1.1188e+00, -3.0773e+00],\n",
       "         [-2.8330e+00, -8.4577e-01, -1.0637e+00,  ..., -2.3205e+00,\n",
       "           2.6245e+00, -8.2585e-01],\n",
       "         ...,\n",
       "         [-1.7195e+00,  1.7569e+00, -7.6966e-01,  ..., -1.3342e+00,\n",
       "          -2.3326e-01, -1.9689e+00],\n",
       "         [-6.4266e+00, -5.7917e+00, -7.3048e-01,  ...,  2.4106e+00,\n",
       "          -2.4566e+00, -7.1773e+00],\n",
       "         [-1.5489e+00,  2.2582e+00, -8.7037e-01,  ...,  2.0526e+00,\n",
       "           1.2427e+00, -2.1785e+00]]], device='cuda:0',\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44a652d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.8472,  -4.0913,   0.2632,  ...,  -4.2332, -10.3623,   0.6719]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
